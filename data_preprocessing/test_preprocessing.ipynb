{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data shape: (12000, 16)\n",
      "✅ Test data preprocessing complete!\n",
      "Final shape: (12000, 18)\n",
      "Missing values: 0\n",
      "Saved as 'processed_dataset/test_data_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Load test data ===\n",
    "test_data = pd.read_csv(\"/Users/rahulsharma/Developer/zelestra_challenge-2/dataset/test.csv\")\n",
    "print(f\"Original test data shape: {test_data.shape}\")\n",
    "\n",
    "# === Step 1: Convert types ===\n",
    "test_data['humidity'] = pd.to_numeric(test_data['humidity'], errors='coerce')\n",
    "test_data['wind_speed'] = pd.to_numeric(test_data['wind_speed'], errors='coerce')\n",
    "test_data['pressure'] = pd.to_numeric(test_data['pressure'], errors='coerce')\n",
    "\n",
    "# === Step 2: Handle missing ===\n",
    "test_data['panel_age'] = test_data.groupby('string_id')['panel_age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "error_string_median = test_data.groupby(['string_id', 'error_code'])['maintenance_count'].median()\n",
    "string_id_median = test_data.groupby('string_id')['maintenance_count'].median()\n",
    "overall_median = test_data['maintenance_count'].median()\n",
    "\n",
    "missing_mask = test_data['maintenance_count'].isna()\n",
    "for idx in test_data[missing_mask].index:\n",
    "    string_id = test_data.loc[idx, 'string_id']\n",
    "    error_code = test_data.loc[idx, 'error_code']\n",
    "    if pd.notna(error_code) and (string_id, error_code) in error_string_median:\n",
    "        test_data.loc[idx, 'maintenance_count'] = error_string_median[(string_id, error_code)]\n",
    "\n",
    "missing_mask = test_data['maintenance_count'].isna()\n",
    "for idx in test_data[missing_mask].index:\n",
    "    string_id = test_data.loc[idx, 'string_id']\n",
    "    if string_id in string_id_median:\n",
    "        test_data.loc[idx, 'maintenance_count'] = string_id_median[string_id]\n",
    "\n",
    "test_data['maintenance_count'].fillna(overall_median, inplace=True)\n",
    "\n",
    "maintenance_bins = pd.cut(test_data['maintenance_count'], bins=5, include_lowest=True)\n",
    "maintenance_soiling_median = test_data.groupby(maintenance_bins, observed=False)['soiling_ratio'].median()\n",
    "\n",
    "missing_soiling_mask = test_data['soiling_ratio'].isna()\n",
    "for idx in test_data[missing_soiling_mask].index:\n",
    "    maintenance_val = test_data.loc[idx, 'maintenance_count']\n",
    "    if pd.notna(maintenance_val):\n",
    "        for bin_range, median_soiling in maintenance_soiling_median.items():\n",
    "            if maintenance_val >= bin_range.left and maintenance_val <= bin_range.right:\n",
    "                test_data.loc[idx, 'soiling_ratio'] = median_soiling\n",
    "                break\n",
    "\n",
    "test_data['soiling_ratio'].fillna(test_data['soiling_ratio'].median(), inplace=True)\n",
    "\n",
    "# === Step 3: Outliers + power ===\n",
    "test_data.loc[test_data['voltage'] > 150, 'voltage'] = np.nan\n",
    "test_data.loc[test_data['current'] > 10, 'current'] = np.nan\n",
    "\n",
    "if test_data[['voltage', 'current']].isna().any().any():\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    test_data[['voltage', 'current']] = imputer.fit_transform(test_data[['voltage', 'current']])\n",
    "\n",
    "test_data['power'] = test_data['current'] * test_data['voltage']\n",
    "\n",
    "# === Step 4: Module temperature prediction ===\n",
    "if test_data['module_temperature'].isna().any():\n",
    "    temp_available = test_data['temperature'].notna()\n",
    "    temp_missing = test_data['module_temperature'].isna()\n",
    "    both_available = temp_available & test_data['module_temperature'].notna()\n",
    "    if both_available.sum() > 10:\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(test_data.loc[both_available, 'temperature'].values.reshape(-1, 1),\n",
    "               test_data.loc[both_available, 'module_temperature'])\n",
    "        predict_mask = temp_missing & temp_available\n",
    "        if predict_mask.any():\n",
    "            test_data.loc[predict_mask, 'module_temperature'] = lr.predict(\n",
    "                test_data.loc[predict_mask, 'temperature'].values.reshape(-1, 1))\n",
    "\n",
    "# === Step 5: KNN imputation for other numerical columns ===\n",
    "numerical_features = ['temperature', 'irradiance', 'module_temperature', 'humidity',\n",
    "                      'cloud_coverage', 'wind_speed', 'pressure']\n",
    "\n",
    "for feature in numerical_features:\n",
    "    if test_data[feature].isna().any():\n",
    "        if feature == 'irradiance':\n",
    "            test_data.loc[test_data[feature] == 0, feature] = np.nan\n",
    "            test_data[feature] = np.clip(test_data[feature], 0, 1500)\n",
    "        elif feature == 'humidity':\n",
    "            test_data.loc[test_data[feature] == 0, feature] = np.nan\n",
    "            test_data[feature] = np.clip(test_data[feature], 0, 100)\n",
    "\n",
    "        related_features = {\n",
    "            'temperature': ['humidity', 'module_temperature', 'irradiance', 'cloud_coverage'],\n",
    "            'irradiance': ['temperature', 'module_temperature', 'humidity', 'cloud_coverage'],\n",
    "            'humidity': ['temperature', 'module_temperature', 'cloud_coverage', 'wind_speed'],\n",
    "            'cloud_coverage': ['temperature', 'humidity', 'irradiance', 'module_temperature'],\n",
    "            'wind_speed': ['temperature', 'humidity', 'pressure', 'cloud_coverage'],\n",
    "            'pressure': ['temperature', 'humidity', 'wind_speed', 'cloud_coverage']\n",
    "        }.get(feature, ['temperature', 'humidity'])\n",
    "\n",
    "        use_features = [f for f in related_features if f in test_data.columns] + [feature]\n",
    "\n",
    "        if len(use_features) > 1:\n",
    "            knn_data = test_data[use_features].apply(pd.to_numeric, errors='coerce')\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            imputed_values = imputer.fit_transform(knn_data)\n",
    "            test_data[feature] = imputed_values[:, -1]\n",
    "        else:\n",
    "            test_data[feature].fillna(test_data[feature].median(), inplace=True)\n",
    "\n",
    "# === Step 6: Handle categoricals ===\n",
    "test_data['error_code'] = test_data['error_code'].fillna('Unknown')\n",
    "test_data['installation_type'] = test_data['installation_type'].fillna('Unknown')\n",
    "\n",
    "# === Step 7: New feature ===\n",
    "test_data['adjusted_irradiance'] = test_data['irradiance'] * test_data['soiling_ratio']\n",
    "\n",
    "# === Step 8: Encode categoricals ===\n",
    "string_id_map = {'A1': 0, 'B2': 1, 'C3': 2, 'D4': 3}\n",
    "error_code_map = {'E00': 0, 'E01': 1, 'E02': 2, 'Unknown': 3}\n",
    "installation_type_map = {'dual-axis': 0, 'fixed': 1, 'tracking': 2, 'Unknown': 3}\n",
    "\n",
    "test_data['string_id_encoded'] = test_data['string_id'].map(string_id_map).fillna(0)\n",
    "test_data['error_code_encoded'] = test_data['error_code'].map(error_code_map).fillna(3)\n",
    "test_data['installation_type_encoded'] = test_data['installation_type'].map(installation_type_map).fillna(3)\n",
    "\n",
    "test_data = test_data.drop(['string_id', 'error_code', 'installation_type'], axis=1)\n",
    "\n",
    "# === Step 9: Scale using saved scaler ===\n",
    "scaler = joblib.load('/Users/rahulsharma/Developer/zelestra_challenge-2/processed_dataset/scaler.joblib')\n",
    "\n",
    "X_test = test_data.drop(['id'], axis=1)\n",
    "\n",
    "# Ensure consistent column order with training\n",
    "X_test = X_test[scaler.feature_names_in_]\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Combine and Save\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=scaler.feature_names_in_)\n",
    "X_test_scaled_df.insert(0, 'id', test_data['id'].values)\n",
    "\n",
    "os.makedirs('processed_dataset', exist_ok=True)\n",
    "X_test_scaled_df.to_csv('processed_dataset/test_data_processed.csv', index=False)\n",
    "\n",
    "print(\"✅ Test data preprocessing complete!\")\n",
    "print(f\"Final shape: {X_test_scaled_df.shape}\")\n",
    "print(f\"Missing values: {X_test_scaled_df.isna().sum().sum()}\")\n",
    "print(\"Saved as 'processed_dataset/test_data_processed.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

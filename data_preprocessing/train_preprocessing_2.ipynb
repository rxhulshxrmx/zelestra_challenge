{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: (20000, 17)\n",
      "✅ Train data preprocessing complete!\n",
      "Final shape: (20000, 19)\n",
      "Missing values: 0\n",
      "Saved as 'processed_dataset/train_data_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === LOAD TRAINING DATA ===\n",
    "train_data = pd.read_csv(\"/Users/rahulsharma/Developer/zelestra_challenge-2/dataset/train.csv\")\n",
    "\n",
    "print(f\"Original training data shape: {train_data.shape}\")\n",
    "\n",
    "# === STEP 1: Convert data types ===\n",
    "train_data['humidity'] = pd.to_numeric(train_data['humidity'], errors='coerce')\n",
    "train_data['wind_speed'] = pd.to_numeric(train_data['wind_speed'], errors='coerce')\n",
    "train_data['pressure'] = pd.to_numeric(train_data['pressure'], errors='coerce')\n",
    "\n",
    "# === STEP 2: Handle missing values ===\n",
    "# 2.1 Panel Age\n",
    "train_data['panel_age'] = train_data.groupby('string_id')['panel_age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# 2.2 Maintenance Count\n",
    "error_string_median = train_data.groupby(['string_id', 'error_code'])['maintenance_count'].median()\n",
    "string_id_median = train_data.groupby('string_id')['maintenance_count'].median()\n",
    "overall_median = train_data['maintenance_count'].median()\n",
    "\n",
    "missing_mask = train_data['maintenance_count'].isna()\n",
    "for idx in train_data[missing_mask].index:\n",
    "    string_id = train_data.loc[idx, 'string_id']\n",
    "    error_code = train_data.loc[idx, 'error_code']\n",
    "    if pd.notna(error_code) and (string_id, error_code) in error_string_median:\n",
    "        train_data.loc[idx, 'maintenance_count'] = error_string_median[(string_id, error_code)]\n",
    "\n",
    "missing_mask = train_data['maintenance_count'].isna()\n",
    "for idx in train_data[missing_mask].index:\n",
    "    string_id = train_data.loc[idx, 'string_id']\n",
    "    if string_id in string_id_median:\n",
    "        train_data.loc[idx, 'maintenance_count'] = string_id_median[string_id]\n",
    "\n",
    "train_data['maintenance_count'].fillna(overall_median, inplace=True)\n",
    "\n",
    "# 2.3 Soiling Ratio\n",
    "maintenance_bins = pd.cut(train_data['maintenance_count'], bins=5, include_lowest=True)\n",
    "maintenance_soiling_median = train_data.groupby(maintenance_bins, observed=False)['soiling_ratio'].median()\n",
    "\n",
    "missing_soiling_mask = train_data['soiling_ratio'].isna()\n",
    "for idx in train_data[missing_soiling_mask].index:\n",
    "    maintenance_val = train_data.loc[idx, 'maintenance_count']\n",
    "    if pd.notna(maintenance_val):\n",
    "        for bin_range, median_soiling in maintenance_soiling_median.items():\n",
    "            if maintenance_val >= bin_range.left and maintenance_val <= bin_range.right:\n",
    "                train_data.loc[idx, 'soiling_ratio'] = median_soiling\n",
    "                break\n",
    "\n",
    "train_data['soiling_ratio'].fillna(train_data['soiling_ratio'].median(), inplace=True)\n",
    "\n",
    "# === STEP 3: Clean outliers and generate power ===\n",
    "train_data.loc[train_data['voltage'] > 150, 'voltage'] = np.nan\n",
    "train_data.loc[train_data['current'] > 10, 'current'] = np.nan\n",
    "\n",
    "if train_data[['voltage', 'current']].isna().any().any():\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    train_data[['voltage', 'current']] = imputer.fit_transform(train_data[['voltage', 'current']])\n",
    "\n",
    "train_data['power'] = train_data['current'] * train_data['voltage']\n",
    "\n",
    "# === STEP 4: Handle other numerical features ===\n",
    "if train_data['module_temperature'].isna().any():\n",
    "    temp_available = train_data['temperature'].notna()\n",
    "    temp_missing = train_data['module_temperature'].isna()\n",
    "    both_available = temp_available & train_data['module_temperature'].notna()\n",
    "\n",
    "    if both_available.sum() > 10:\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(train_data.loc[both_available, 'temperature'].values.reshape(-1, 1),\n",
    "               train_data.loc[both_available, 'module_temperature'])\n",
    "\n",
    "        predict_mask = temp_missing & temp_available\n",
    "        if predict_mask.any():\n",
    "            train_data.loc[predict_mask, 'module_temperature'] = lr.predict(\n",
    "                train_data.loc[predict_mask, 'temperature'].values.reshape(-1, 1))\n",
    "\n",
    "numerical_features = ['temperature', 'irradiance', 'module_temperature', 'humidity',\n",
    "                      'cloud_coverage', 'wind_speed', 'pressure']\n",
    "\n",
    "for feature in numerical_features:\n",
    "    if train_data[feature].isna().any():\n",
    "        if feature == 'irradiance':\n",
    "            train_data.loc[train_data[feature] == 0, feature] = np.nan\n",
    "            train_data[feature] = np.clip(train_data[feature], 0, 1500)\n",
    "        elif feature == 'humidity':\n",
    "            train_data.loc[train_data[feature] == 0, feature] = np.nan\n",
    "            train_data[feature] = np.clip(train_data[feature], 0, 100)\n",
    "\n",
    "        if feature == 'temperature':\n",
    "            related_features = ['humidity', 'module_temperature', 'irradiance', 'cloud_coverage']\n",
    "        elif feature == 'irradiance':\n",
    "            related_features = ['temperature', 'module_temperature', 'humidity', 'cloud_coverage']\n",
    "        elif feature == 'humidity':\n",
    "            related_features = ['temperature', 'module_temperature', 'cloud_coverage', 'wind_speed']\n",
    "        elif feature == 'cloud_coverage':\n",
    "            related_features = ['temperature', 'humidity', 'irradiance', 'module_temperature']\n",
    "        elif feature == 'wind_speed':\n",
    "            related_features = ['temperature', 'humidity', 'pressure', 'cloud_coverage']\n",
    "        elif feature == 'pressure':\n",
    "            related_features = ['temperature', 'humidity', 'wind_speed', 'cloud_coverage']\n",
    "        else:\n",
    "            related_features = ['temperature', 'humidity']\n",
    "\n",
    "        use_features = [f for f in related_features if f in train_data.columns] + [feature]\n",
    "\n",
    "        if len(use_features) > 1:\n",
    "            knn_data = train_data[use_features].apply(pd.to_numeric, errors='coerce')\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            imputed_values = imputer.fit_transform(knn_data)\n",
    "            train_data[feature] = imputed_values[:, -1]\n",
    "        else:\n",
    "            train_data[feature].fillna(train_data[feature].median(), inplace=True)\n",
    "\n",
    "# === STEP 5: Handle categoricals ===\n",
    "train_data['error_code'] = train_data['error_code'].fillna('Unknown')\n",
    "train_data['installation_type'] = train_data['installation_type'].fillna('Unknown')\n",
    "\n",
    "# === STEP 6: Generate additional features ===\n",
    "train_data['adjusted_irradiance'] = train_data['irradiance'] * train_data['soiling_ratio']\n",
    "\n",
    "# === STEP 7: Encode categoricals ===\n",
    "string_id_map = {'A1': 0, 'B2': 1, 'C3': 2, 'D4': 3}\n",
    "error_code_map = {'E00': 0, 'E01': 1, 'E02': 2, 'Unknown': 3}\n",
    "installation_type_map = {'dual-axis': 0, 'fixed': 1, 'tracking': 2, 'Unknown': 3}\n",
    "\n",
    "train_data['string_id_encoded'] = train_data['string_id'].map(string_id_map).fillna(0)\n",
    "train_data['error_code_encoded'] = train_data['error_code'].map(error_code_map).fillna(3)\n",
    "train_data['installation_type_encoded'] = train_data['installation_type'].map(installation_type_map).fillna(3)\n",
    "\n",
    "train_data = train_data.drop(['string_id', 'error_code', 'installation_type'], axis=1)\n",
    "\n",
    "# === STEP 8: Separate label and scale ===\n",
    "label = train_data['efficiency']  # Replace 'target' with actual target column name\n",
    "X = train_data.drop(['id', 'efficiency'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create directory before saving\n",
    "os.makedirs('processed_dataset', exist_ok=True)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'processed_dataset/scaler.joblib')\n",
    "\n",
    "\n",
    "# Combine and save\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled_df.insert(0, 'id', train_data['id'].values)\n",
    "X_scaled_df['target'] = label.values\n",
    "\n",
    "os.makedirs('processed_dataset', exist_ok=True)\n",
    "X_scaled_df.to_csv('processed_dataset/train_data_processed.csv', index=False)\n",
    "\n",
    "print(\"✅ Train data preprocessing complete!\")\n",
    "print(f\"Final shape: {X_scaled_df.shape}\")\n",
    "print(f\"Missing values: {X_scaled_df.isna().sum().sum()}\")\n",
    "print(\"Saved as 'processed_dataset/train_data_processed.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

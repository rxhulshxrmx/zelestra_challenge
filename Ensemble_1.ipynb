{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will work on Nvidia's GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from cuml.ensemble import RandomForestRegressor as cuRandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import joblib\n",
    "\n",
    "# Load your training dataset\n",
    "train_df = pd.read_csv('/kaggle/input/solar-panels-performance/dataset/cleaned_data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = train_df.drop('efficiency', axis=1)\n",
    "y = train_df['efficiency']\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target range: {y.min():.3f} to {y.max():.3f}\")\n",
    "print(f\"Target mean: {y.mean():.3f}, std: {y.std():.3f}\")\n",
    "\n",
    "# Feature scaling for models that need it\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the ImprovedStackingRegressor class\n",
    "class ImprovedStackingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_models, meta_model, use_scaling=True):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.use_scaling = use_scaling\n",
    "        if use_scaling:\n",
    "            self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.use_scaling:\n",
    "            X_processed = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X_processed = X\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        base_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            fold_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                if i < 1:  # Only the first model uses scaled data\n",
    "                    X_train_fold = X_processed[train_idx]\n",
    "                    X_val_fold = X_processed[val_idx]\n",
    "                else:\n",
    "                    X_train_fold = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]\n",
    "                    X_val_fold = X.iloc[val_idx] if hasattr(X, 'iloc') else X[val_idx]\n",
    "\n",
    "                y_train_fold = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx]\n",
    "\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                fold_predictions[val_idx] = model.predict(X_val_fold)\n",
    "\n",
    "            base_predictions[:, i] = fold_predictions\n",
    "\n",
    "        self.meta_model.fit(base_predictions, y)\n",
    "\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            if i < 1:\n",
    "                model.fit(X_processed, y)\n",
    "            else:\n",
    "                model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.use_scaling:\n",
    "            X_processed = self.scaler.transform(X)\n",
    "        else:\n",
    "            X_processed = X\n",
    "\n",
    "        base_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            if i < 1:\n",
    "                base_predictions[:, i] = model.predict(X_processed)\n",
    "            else:\n",
    "                base_predictions[:, i] = model.predict(X)\n",
    "\n",
    "        return self.meta_model.predict(base_predictions)\n",
    "\n",
    "# Define optimized base models with better hyperparameters\n",
    "base_models = [\n",
    "    XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method='hist',  # Use 'hist' tree method\n",
    "        device='cuda'  # Set device to CUDA for GPU training\n",
    "    ),\n",
    "    cuRandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        random_state=42,\n",
    "        n_streams=1  # Set n_streams to 1 for reproducibility\n",
    "    ),\n",
    "    cuRandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=20,\n",
    "        random_state=123,\n",
    "        n_streams=1  # Set n_streams to 1 for reproducibility\n",
    "    )\n",
    "]\n",
    "\n",
    "# Use Ridge regression as meta-model\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Create stacking model\n",
    "stacking_model = ImprovedStackingRegressor(\n",
    "    base_models=base_models,\n",
    "    meta_model=meta_model,\n",
    "    use_scaling=True\n",
    ")\n",
    "\n",
    "# Define the same scoring method as your original code\n",
    "def custom_score(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return 100 * (1 - np.sqrt(mse))\n",
    "\n",
    "scorer = make_scorer(custom_score, greater_is_better=True)\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Test individual models first\n",
    "print(\"\\n=== Individual Model Performance ===\")\n",
    "for i, model in enumerate(base_models):\n",
    "    if i < 1:\n",
    "        cv_scores = cross_val_score(model, X_scaled, y, cv=kfold, scoring=scorer)\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X, y, cv=kfold, scoring=scorer)\n",
    "\n",
    "    print(f\"Model {i+1} CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\")\n",
    "\n",
    "# Test the stacking ensemble\n",
    "print(\"\\n=== Stacking Ensemble Performance ===\")\n",
    "cv_scores = cross_val_score(stacking_model, X, y, cv=kfold, scoring=scorer)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", [f\"{score:.3f}\" for score in cv_scores])\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.3f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.3f}\")\n",
    "\n",
    "# Train final model\n",
    "print(\"\\n=== Training Final Model ===\")\n",
    "stacking_model.fit(X, y)\n",
    "\n",
    "# Save the model\n",
    "model_path = '/kaggle/working/optimized_ensemble_model.pkl'\n",
    "joblib.dump(stacking_model, model_path)\n",
    "print(f\"Model saved as '{model_path}'\")\n",
    "\n",
    "# Load the test data\n",
    "test_data_path = '/kaggle/input/solar-panels-performance/dataset/test_data_processed.csv'\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# Ensure the test data has the same features as the training data\n",
    "feature_columns = X.columns\n",
    "test_df_aligned = test_df[feature_columns]\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = stacking_model.predict(test_df_aligned)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'efficiency': predictions\n",
    "})\n",
    "\n",
    "# Save the submission file in the /kaggle/working/ directory\n",
    "submission_path = '/kaggle/working/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "# Check if the file exists and print its size\n",
    "if os.path.exists(submission_path):\n",
    "    file_size = os.path.getsize(submission_path)\n",
    "    print(f\"Submission file saved as {submission_path} with size {file_size} bytes.\")\n",
    "else:\n",
    "    print(f\"Failed to save the submission file at {submission_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
